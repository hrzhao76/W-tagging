{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubles\n",
    "\n",
    "### Cannot archieve the same performance as paper \n",
    "\n",
    "Paper: https://arxiv.org/abs/1603.09349  \n",
    "My code: https://github.com/hrzhao76/W-tagging/blob/master/NN/NN-Paper-tf.py  \n",
    "\n",
    "\n",
    "#### Configurations in paper: \n",
    "\n",
    "Frame: Keras and Theano\n",
    "\n",
    "4 locally-connected layers, followded by 4 fully-connected layers 425 units per layers\n",
    "\n",
    "hidden layers: tanh units logistic output Cross-entropy loss\n",
    "\n",
    "ADAM optimizer: Beta_1 = 0.9, Beta 2 = 0.999, epsilon = 1e-08 Minimum batches of size 100\n",
    "\n",
    "Weights normal distribution\n",
    "\n",
    "learning rate 0.0001 decay factor 0.9 maximum 50 epochs\n",
    "\n",
    "training dataset : 10 million examples validation set: 500 thousand Test dataset: 5 million examples\n",
    "\n",
    "\n",
    "\n",
    "#### My codes to set the architecture:\n",
    "\n",
    "``` python\n",
    "model = keras.Sequential([\n",
    "    keras.layers.LocallyConnected2D(32,(4,4),activation='tanh', input_shape=(1, 32, 32), kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)),\n",
    "    keras.layers.LocallyConnected2D(32,(4,4),activation='tanh'),\n",
    "    keras.layers.LocallyConnected2D(32,(4,4),activation='tanh'),\n",
    "    keras.layers.LocallyConnected2D(32,(4,4),activation='tanh'),\n",
    "    \n",
    "    \n",
    "    keras.layers.Flatten(), # \n",
    "\n",
    "    keras.layers.Dense(425, activation='tanh'),\n",
    "    keras.layers.Dense(425, activation='tanh'),\n",
    "    keras.layers.Dense(425, activation='tanh'),\n",
    "    keras.layers.Dense(425, activation='tanh'),\n",
    "    \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.9, amsgrad=False)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"OK!, then fit!\")\n",
    "history = model.fit(train_images, train_labels, validation_split = 0.1, batch_size = 100, epochs=50, verbose=1)\n",
    "\n",
    "```\n",
    "#### performance\n",
    "\n",
    "my codes tested on 10k samples:\n",
    "![Alt text](./test/NN_10k/performance.png) \n",
    "\n",
    "-> Should be more stat\n",
    "\n",
    "However, \n",
    "my codes tested on 100k samples:\n",
    "![Alt text](./test/NN_100k/performance_100k.png)\n",
    "![Alt text](./test/NN_100k/AUC.png)\n",
    "\n",
    "Authors of the paper use 10 million samples to train the network and the AUC is 0.953 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
